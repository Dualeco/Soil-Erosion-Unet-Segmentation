# -*- coding: utf-8 -*-
"""QuantumTask4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beV1ErRkvVQnFSosi-twWhqmML15Houh
"""

"""#1. First. process the raster and shapes as per the acticle mentioned in the task"""

# Commented out IPython magic to ensure Python compatibility.
import os

import rasterio
from rasterio.plot import reshape_as_image
import rasterio.mask
from rasterio.features import rasterize

import pandas as pd
import geopandas as gpd
from shapely.geometry import mapping, Point, Polygon
from shapely.ops import cascaded_union

import numpy as np
import cv2
import matplotlib.pyplot as plt

# %matplotlib inline

"""Reading Raster with rasterio"""

raster_path = "T36UXV_20200406T083559_TCI_10m.jp2"
src = rasterio.open(raster_path, "r", driver="JP2OpenJPEG")
raster_img = reshape_as_image(src.read())
raster_meta = src.meta

"""Checking Raster shape and Meta"""

train_df = gpd.read_file("shpnew.gpkg")

# let's remove rows without geometry
train_df = train_df[~train_df.geometry.is_empty & train_df.geometry.notna()]

train_df

# rasterize works with polygons that are in image coordinate system

def poly_from_utm(polygon, transform):
    poly_pts = []
    
    # make a polygon from multipolygon
    poly = cascaded_union(polygon)
    for i in np.array(poly.exterior.coords):
        
        # transfrom polygon to image crs, using raster meta
        poly_pts.append(~transform * tuple(i))
        
    # make a shapely Polygon object
    new_poly = Polygon(poly_pts)
    return new_poly

# creating binary mask for field/not_filed segmentation.

poly_shp = []
im_size = (src.meta['height'], src.meta['width'])
for num, row in train_df.iterrows():
    if row['geometry'].geom_type == 'Polygon':
        poly = poly_from_utm(row['geometry'], src.meta['transform'])
        poly_shp.append(poly)
    else:
        for p in row['geometry']:
            poly = poly_from_utm(p, src.meta['transform'])
            poly_shp.append(poly)

mask = rasterize(shapes=poly_shp,
                 out_shape=im_size)

"""Using rasterio reshape to plot an image in matplotlib"""

#bin_mask_meta = src.meta.copy()
#bin_mask_meta.update({'count': 1})
#with rasterio.open("train.jp2", 'w', **bin_mask_meta) as dst:
#    dst.write(mask * 255, 1)

np.unique(mask)

"""# 2. Data Augmentation

# Let's split the large image into patches of 256x256
"""

masks = []
#empty_masks = []

rasters = []
#empty_rasters = []

for i in range(0, len(mask) - 256, 64):
    for j in range(0, len(mask) - 256, 64):
      m = mask[i: i + 256, j: j + 256]
      r = raster_img[i: i + 256, j: j + 256]
      _, counts = np.unique(m, return_counts=True)
      if (counts[0] / counts.sum() < 0.99):
        masks.append(m)
        rasters.append(r)

len(masks)

plt.imshow(rasters[112])

plt.imshow(masks[202])

"""# Add flipped images, add rotatated images"""

for i in range(len(masks)):
  masks.append(np.fliplr(masks[i]))
  rasters.append(np.fliplr(rasters[i]))

for i in range(len(masks)):
  masks.append(np.rot90(masks[i]))
  #masks.append(np.rot90(masks[-1]))
  #masks.append(np.rot90(masks[-1]))

  rasters.append(np.rot90(rasters[i]))
  #rasters.append(np.rot90(rasters[-1]))
  #rasters.append(np.rot90(rasters[-1]))

"""#Data Augmentation finished"""

len(masks), len(rasters)

"""# 3. Training the model

#We will use U-net for this image segmentation problem
"""

rasters[0].shape

# Building Unet by dividing encoder and decoder into blocks
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Activation, MaxPool2D, Concatenate


def conv_block(input, num_filters):
    x = Conv2D(num_filters, 3, padding="same")(input)
    x = BatchNormalization()(x)   #Not in the original network. 
    x = Activation("relu")(x)

    x = Conv2D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)  #Not in the original network
    x = Activation("relu")(x)

    return x

#Encoder block: Conv block followed by maxpooling


def encoder_block(input, num_filters):
    x = conv_block(input, num_filters)
    p = MaxPool2D((2, 2))(x)
    return x, p   

#Decoder block
#skip features gets input from encoder for concatenation

def decoder_block(input, skip_features, num_filters):
    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding="same")(input)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x

#Build Unet using the blocks
def build_unet(input_shape, n_classes):
    inputs = Input(input_shape)

    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    b1 = conv_block(p4, 1024) #Bridge

    d1 = decoder_block(b1, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)
    
    activation = 'sigmoid'

    outputs = Conv2D(1, 1, padding="same", activation=activation)(d4)  #Change the activation based on n_classes
    print(activation)

    model = Model(inputs, outputs, name="U-Net")
    return model

input_shape = (256, 256, 3)

from keras import backend as K
def jaccard_distance(y_true, y_pred, smooth=100):
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return (1 - jac) * smooth

"""# The model uses adam optimizer, binary crossentropy loss, intersection over union as a metric"""

from tensorflow.keras.metrics import MeanIoU

model = build_unet(input_shape, n_classes=1)
model.compile(optimizer=Adam(learning_rate = 1e-3), loss='binary_crossentropy', metrics=[MeanIoU(num_classes=2)])
model.summary()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(rasters, masks, test_size = 0.1)
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)

len(masks)

from tensorflow.keras.callbacks import EarlyStopping

v_data = (np.array(X_valid), np.array(y_valid))
history = model.fit(np.array(X_train), np.array(y_train), 
                    batch_size = 16, 
                    verbose=1, 
                    epochs=20, 
                    validation_data=v_data, 
                    shuffle=False,
                    callbacks=[EarlyStopping(patience=10)])

model.save('model.hdf5')

"""# Test masks"""

idx =  np.random.randint(len(y_test), size=24)

f, axarr = plt.subplots(3, 8)
f.set_size_inches(40, 15)
for i in range(len(idx)):
  axarr[i % 3, i % 8].imshow(y_test[idx[i]])

"""#Predicted masks

# We will use threshold of 0.5 to separate bright pixels from dark ones
"""

f, axarr = plt.subplots(3, 8)
f.set_size_inches(40, 15)
for i in range(len(idx)):
  axarr[i % 3, i % 8].imshow(pred[idx[i]][:, :, 0] > 0.5)

pred_bin = pred[:, :, :, 0] > 0.5

loss = MeanIoU(num_classes=2)
loss.update_state(y_test, pred_bin)

loss.result().numpy()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt

"""# Mean IoU is over 92%!"""
